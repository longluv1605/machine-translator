{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9h1xGMPjLUl"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZitYsEDop1ra",
        "outputId": "a8979f86-7fb4-4f2c-a885-a17b84d483f2"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7HCAW5pfr_c",
        "outputId": "872a2a2f-9b15-4412-e403-fce57325a403"
      },
      "outputs": [],
      "source": [
        "# %pip install datasets transformers evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SdEdJ8iBcs4R"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the TF-Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\applications\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\applications\\convnext.py:26\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\__init__.py:85\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_data_flow_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_stitch \u001b[38;5;66;03m# line: 827\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_experimental_dataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_pinned \u001b[38;5;66;03m# line: 725\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_linalg_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m matrix_square_root \u001b[38;5;66;03m# line: 2108\u001b[39;00m\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'check_pinned' from 'tensorflow.python.ops.gen_experimental_dataset_ops' (c:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_experimental_dataset_ops.py)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1817\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
            "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1817\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1805\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1819\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1820\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1822\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1817\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     get_reporting_integration_callbacks,\n\u001b[0;32m     44\u001b[0m     hp_params,\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1805\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1819\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1820\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1822\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, MBartForConditionalGeneration, MBart50TokenizerFast, TrainingArguments, Trainer\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1805\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1803\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
            "File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1819\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1820\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1822\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import datasets\n",
        "import tqdm\n",
        "import evaluate\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from transformers import AutoTokenizer, MBartForConditionalGeneration, MBart50TokenizerFast, TrainingArguments, Trainer\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fpCFKEfMfdEz"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyqYI6KOjJoz"
      },
      "source": [
        "# I - Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrTTtLW_f_Oa",
        "outputId": "26cbb083-da0b-402d-d152-f7d1dffd268e"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.load_dataset(\"harouzie/vi_en-translation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-1KX4F09gHKs"
      },
      "outputs": [],
      "source": [
        "train_data, test_data, valid_data = (dataset['train'], dataset['test'], dataset['valid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cabnB9dTgTxi",
        "outputId": "51b6adaa-7c1e-4f8d-e682-7830dc3acc37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'English': 'The pharmacy is on Fresno Street',\n",
              " 'Vietnamese': 'hiệu thuốc nằm trên đường fresno'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpW_OaaKjzOb"
      },
      "source": [
        "# II - Setup tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LXJDRzAjpHPo"
      },
      "outputs": [],
      "source": [
        "UNK_TOKEN = \"<unk>\"\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "BOS_TOKEN = \"<s>\"\n",
        "EOS_TOKEN = \"</s>\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fyyj0dWljyoo"
      },
      "outputs": [],
      "source": [
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\",\n",
        "\t\t\t\t\t\t\t\t\t\t  unk_token=UNK_TOKEN,\n",
        "\t\t\t\t\t\t\t\t\t\t  pad_token=PAD_TOKEN,\n",
        "\t\t\t\t\t\t\t\t\t\t  bos_token=BOS_TOKEN,\n",
        "\t\t\t\t\t\t\t\t\t\t  eos_token=EOS_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1-gSJMF7_wX",
        "outputId": "b49e8e4c-5eb2-433b-9c9b-d24969e8bfc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [250004, 6842, 19621, 33937, 2479, 7590, 73989, 157, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer('hiệu thuốc nằm trên đường fresno')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkp1-W6s7_wX",
        "outputId": "8d8da716-f245-45e5-dca2-91a67ec505f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "250054"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xenk2YduocNE"
      },
      "source": [
        "# III - Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0sc8WjzCllJX"
      },
      "outputs": [],
      "source": [
        "def convert_to_ids(example, tokenizer):\n",
        "\ten_ids = tokenizer(example[\"English\"], truncation=True)\n",
        "\tvi_ids = tokenizer(example[\"Vietnamese\"], truncation=True)\n",
        "\treturn {\"en_ids\": en_ids['input_ids'], \"vi_ids\": vi_ids['input_ids']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "7a97c9e21de8469097cf9151dee05151",
            "c84cf45f82394072a7a24dfa4cf48c81",
            "3aa32e6fcd284126bd8e4955fab735a3",
            "62ce97c2b1df444a84712ad88caf8744",
            "a2fbf9bc93e649de8339dcf9c6daebb2",
            "136dd050721246c4bb584d83c4125210",
            "42824743e3e5449b8885a85ab17e29a5",
            "e6c3a7061dd545218cf5e2805366213f",
            "83787ea2b309464d9afc0257079573e8",
            "abdd3e9d73684da788ba25a56effe28f",
            "2a70df98f70f4f51aeb861c1ca3e3243"
          ]
        },
        "id": "2kVnlbfonLuj",
        "outputId": "fb2a37c6-98a8-4929-d702-d93e0f82f208"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bbfc97ea520463f886e135887f979d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/25409 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "fn_kwargs = {\"tokenizer\":tokenizer}\n",
        "\n",
        "train_data = train_data.map(convert_to_ids, fn_kwargs=fn_kwargs)\n",
        "valid_data = valid_data.map(convert_to_ids, fn_kwargs=fn_kwargs)\n",
        "test_data = test_data.map(convert_to_ids, fn_kwargs=fn_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M_v5mrv9lebb"
      },
      "outputs": [],
      "source": [
        "DATA_TYPE = \"torch\"\n",
        "format_columns = [\"en_ids\", \"vi_ids\"]\n",
        "\n",
        "train_data = train_data.with_format(\n",
        "\ttype=DATA_TYPE, columns=format_columns, output_all_columns=True\n",
        ")\n",
        "\n",
        "valid_data = valid_data.with_format(\n",
        "\ttype=DATA_TYPE,\n",
        "\tcolumns=format_columns,\n",
        "\toutput_all_columns=True,\n",
        ")\n",
        "\n",
        "test_data = test_data.with_format(\n",
        "\ttype=DATA_TYPE,\n",
        "\tcolumns=format_columns,\n",
        "\toutput_all_columns=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0hI68iYHoY4f"
      },
      "outputs": [],
      "source": [
        "def get_collate_fn(pad_index):\n",
        "\tdef collate_fn(batch):\n",
        "\t\tbatch_en_ids = [example[\"en_ids\"] for example in batch]\n",
        "\t\tbatch_vi_ids = [example[\"vi_ids\"] for example in batch]\n",
        "\t\tbatch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
        "\t\tbatch_vi_ids = nn.utils.rnn.pad_sequence(batch_vi_ids, padding_value=pad_index)\n",
        "\t\tbatch_en_ids[0] = 0\n",
        "\t\tbatch_vi_ids[0] = 0\n",
        "\t\tbatch = {\n",
        "\t\t\t\"en_ids\": batch_en_ids.transpose(-2, -1),\n",
        "\t\t\t\"vi_ids\": batch_vi_ids.transpose(-2, -1),\n",
        "\t\t}\n",
        "\t\treturn batch\n",
        "\n",
        "\treturn collate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W6Oj9EchoemO"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(dataset, batch_size, pad_index, shuffle=False):\n",
        "\tcollate_fn = get_collate_fn(pad_index)\n",
        "\tdata_loader = torch.utils.data.DataLoader(\n",
        "\t\tdataset=dataset,\n",
        "\t\tbatch_size=batch_size,\n",
        "\t\tcollate_fn=collate_fn,\n",
        "\t\tshuffle=shuffle,\n",
        "\t)\n",
        "\treturn data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "a8lEx1dWqqA-"
      },
      "outputs": [],
      "source": [
        "PAD_INDEX = tokenizer.pad_token_id\n",
        "UNK_INDEX = tokenizer.unk_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UCBRB85kogMb"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataloader = get_dataloader(train_data, BATCH_SIZE, PAD_INDEX, shuffle=True)\n",
        "valid_dataloader = get_dataloader(valid_data, BATCH_SIZE, PAD_INDEX)\n",
        "test_dataloader = get_dataloader(test_data, BATCH_SIZE, PAD_INDEX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Yfri8M75xXQ9"
      },
      "outputs": [],
      "source": [
        "# del train_data, valid_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2vrMOLi7_wY",
        "outputId": "214989ab-cf7e-41d2-c8f8-df19d0d9d13b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([     0,   3293,  18276,     83, 170277,      2,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1])\n",
            "tensor([    0, 57658,  2455,  1617, 18844,  9457,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "print(batch['en_ids'][0])\n",
        "print(batch['vi_ids'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUMLhaJ_sEfn"
      },
      "source": [
        "# IV - Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiAHIQRy7_wY",
        "outputId": "edc326eb-d0e6-4728-c7c1-02b2e16fad01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 512])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Embedding(nn.Module):\n",
        "\tdef __init__(self, vocab_size, model_dim):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.vocab_size = vocab_size\n",
        "\t\tself.model_dim = model_dim\n",
        "\t\tself.emb = nn.Embedding(vocab_size, model_dim)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\treturn self.emb(x)\n",
        "\n",
        "Embedding(100, 512)(torch.LongTensor([1,2,3,4])).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQVgtoU67_wY",
        "outputId": "a1c48653-977d-4b1c-b7e5-0aa2a2108a89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 30, 512])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\tdef __init__(self, model_dim, max_seq_len=144, dropout=0.2):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.model_dim = model_dim\n",
        "\t\tself.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\t\tpos_enc = torch.zeros(max_seq_len, model_dim)\n",
        "\n",
        "\t\tfor pos in range(max_seq_len):\n",
        "\t\t\tfor i in range(0, model_dim, 2):\n",
        "\t\t\t\tpos_enc[pos, i] = math.sin(pos / (10000 ** (i / model_dim)))\n",
        "\t\t\t\tpos_enc[pos, i + 1] = math.cos(pos / (10000 ** (i / model_dim)))\n",
        "\t\tpos_enc.unsqueeze(0)\n",
        "\t\tself.register_buffer('pos_enc', pos_enc)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = x * math.sqrt(self.model_dim)\n",
        "\t\tseq_len = x.size(1)\n",
        "\t\tpos_enc = Variable(self.pos_enc[:seq_len], requires_grad=True)\n",
        "\n",
        "\t\tif x.is_cuda:\n",
        "\t\t\tpos_enc.cuda()\n",
        "\t\tx = x + pos_enc\n",
        "\t\tx = self.dropout(x)\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "PositionalEncoding(512)(torch.rand(5, 30, 512)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkSQ9_Oc7_wY",
        "outputId": "4c8eb57a-0dfa-41fc-cb1f-0c1241cbad8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 8, 30, 512]) torch.Size([32, 8, 30, 30])\n"
          ]
        }
      ],
      "source": [
        "def self_attention(query, key, value, mask=None, dropout=None):\n",
        "\t\"\"\"\n",
        "\tq: [batch_size, head, seq_len, model_dim]\n",
        "\tk: [batch_size, head, seq_len, model_dim]\n",
        "\tv: [batch_size, head, seq_len, model_dim]\n",
        "\tmask: [batch_size, 1, seq_len]\n",
        "\toutput: [batch_size, head, seq_len, model_dim]\n",
        "\t\"\"\"\n",
        "\n",
        "\tk_dim = key.size(1)\n",
        "\tscores = torch.matmul(query, key.transpose(-2, -1)) /  math.sqrt(k_dim)\n",
        "\n",
        "\t# Handle mask for Decoding\n",
        "\tif mask is not None:\n",
        "\t\tmask = mask.unsqueeze(1)\n",
        "\t\tscores = scores.masked_fill(mask==0, -1e4)\n",
        "\n",
        "\tscores = F.softmax(scores, dim=-1)\n",
        "\n",
        "\tif dropout is not None:\n",
        "\t\tscores = dropout(scores)\n",
        "\n",
        "\toutput = torch.matmul(scores, value)\n",
        "\treturn output, scores\n",
        "\n",
        "test_output, test_scores = self_attention(torch.rand(32, 8, 30, 512), torch.rand(32, 8, 30, 512), torch.rand(32, 8, 30, 512))\n",
        "print(test_output.shape, test_scores.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uf2EFnS7_wY",
        "outputId": "fd860523-5fc5-4284-d927-98bc9b998ea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 30, 512])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\tdef __init__(self, num_heads, model_dim, dropout=0.2):\n",
        "\t\tsuper().__init__()\n",
        "\t\tassert model_dim % num_heads == 0, \"Number of heads must be divisor of model dim\"\n",
        "\n",
        "\t\tself.model_dim = model_dim\n",
        "\t\tself.k_dim = model_dim // num_heads\n",
        "\t\tself.num_heads = num_heads\n",
        "\t\tself.attn = None\n",
        "\n",
        "\t\tself.W_q = nn.Linear(model_dim, model_dim)\n",
        "\t\tself.W_k = nn.Linear(model_dim, model_dim)\n",
        "\t\tself.W_v = nn.Linear(model_dim, model_dim)\n",
        "\t\tself.out = nn.Linear(model_dim, model_dim)\n",
        "\n",
        "\t\tself.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\tdef forward(self, query, key, value, mask=None):\n",
        "\t\t\"\"\"\n",
        "\t\tq: [batch_size, seq_len, model_dim]\n",
        "\t\tk: [batch_size, seq_len, model_dim]\n",
        "\t\tv: [batch_size, seq_len, model_dim]\n",
        "\t\tmask: [batch_size, 1, seq_len]\n",
        "\t\toutput: [batch_size, seq_len, model_dim]\n",
        "\t\t\"\"\"\n",
        "\t\tbatch_size = query.size(0)\n",
        "\t\tquery = self.W_q(query).view(batch_size, -1, self.num_heads, self.k_dim).transpose(1, 2)\n",
        "\t\tkey = self.W_k(key).view(batch_size, -1, self.num_heads, self.k_dim).transpose(1, 2)\n",
        "\t\tvalue = self.W_v(value).view(batch_size, -1, self.num_heads, self.k_dim).transpose(1, 2)\n",
        "\n",
        "\t\tscores, self.attn = self_attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "\t\tconcat = scores.transpose(1, 2).contiguous().view(batch_size, -1, self.model_dim)\n",
        "\t\toutput = self.out(concat)\n",
        "\n",
        "\t\treturn output\n",
        "\n",
        "MultiHeadAttention(8, 512)(torch.rand(32, 30, 512), torch.rand(32, 30, 512), torch.rand(32, 30, 512)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ih1xZJu27_wZ"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "\tdef __init__(self, model_dim, ff_dim=1024, dropout=0.2):\n",
        "\t\tsuper().__init__()\n",
        "\n",
        "\t\tself.linear_1 = nn.Linear(model_dim, ff_dim)\n",
        "\t\tself.dropout = nn.Dropout(dropout)\n",
        "\t\tself.linear_2 = nn.Linear(ff_dim, model_dim)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.linear_1(x)\n",
        "\t\tx = self.dropout(F.relu(x))\n",
        "\t\tx = self.linear_2(x)\n",
        "\t\treturn x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL6RE67e7_wZ",
        "outputId": "fc6e7ef9-09fc-4337-b296-e5f32969595e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 30, 512])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\tdef __init__(self, model_dim, num_heads, ff_dim=1024, dropout=0.2):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.norm_1 = nn.LayerNorm(model_dim)\n",
        "\t\tself.norm_2 = nn.LayerNorm(model_dim)\n",
        "\t\tself.attn = MultiHeadAttention(num_heads, model_dim, dropout)\n",
        "\t\tself.ffn = FeedForward(model_dim, ff_dim, dropout)\n",
        "\t\tself.dropout_1 = nn.Dropout(dropout)\n",
        "\t\tself.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "\tdef forward(self, x, mask):\n",
        "\n",
        "\t\t# Attention\n",
        "\t\tx2 = self.norm_1(x)\n",
        "\t\tx = x + self.dropout_1(self.attn(x2, x2, x2, mask))\n",
        "\n",
        "\t\t# Feed forward\n",
        "\t\tx2 = self.norm_2(x)\n",
        "\t\tx = x + self.dropout_2(self.ffn(x2))\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "EncoderLayer(512, 8)(torch.rand(32, 30, 512), torch.rand(32 , 1, 30)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPxk_gcZ7_wZ",
        "outputId": "b2eb74e3-8c41-4301-dd43-7b5137d990fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 30, 512])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\tdef __init__(self, model_dim, num_heads, ff_dim=1024, dropout=0.2):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.norm_1 = nn.LayerNorm(model_dim)\n",
        "\t\tself.norm_2 = nn.LayerNorm(model_dim)\n",
        "\t\tself.norm_3 = nn.LayerNorm(model_dim)\n",
        "\n",
        "\t\tself.dropout_1 = nn.Dropout(dropout)\n",
        "\t\tself.dropout_2 = nn.Dropout(dropout)\n",
        "\t\tself.dropout_3 = nn.Dropout(dropout)\n",
        "\n",
        "\t\tself.attn_1 = MultiHeadAttention(num_heads, model_dim, dropout)\n",
        "\t\tself.attn_2 = MultiHeadAttention(num_heads, model_dim, dropout)\n",
        "\t\tself.ffn = FeedForward(model_dim, ff_dim, dropout)\n",
        "\n",
        "\tdef forward(self, x, enc_output, src_mask, trg_mask):\n",
        "\t\t\"\"\"\n",
        "\t\tx: [batch_size, seq_len, model_dim]\n",
        "\t\te_outputs: [batch_size, seq_len, model_dim]\n",
        "\t\tsrc_mask: [batch_size, 1, seq_len]\n",
        "\t\ttrg_mask: [batch_size, 1, seq_len]\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Attention 1\n",
        "\t\tx2 = self.norm_1(x)\n",
        "\t\tx = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
        "\n",
        "\t\t# Attention 2\n",
        "\t\tx2 = self.norm_2(x)\n",
        "\t\tx = x + self.dropout_2(self.attn_2(x2, enc_output, enc_output, src_mask))\n",
        "\n",
        "\t\t# FFN\n",
        "\t\tx2 = self.norm_3(x)\n",
        "\t\tx = x + self.dropout_3(self.ffn(x2))\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "DecoderLayer(512, 8)(torch.rand(32, 30, 512), torch.rand(32, 30, 512), torch.rand(32, 1, 30), torch.rand(32, 1, 30)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ngXFBVQ7_wZ",
        "outputId": "316119f1-e3fc-4ee8-c3d4-5309f675a566"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 30, 512])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Encoder(nn.Module):\n",
        "\tdef __init__(self, vocab_size, model_dim, N_layers, num_heads, max_seq_len=144, ff_dim=1024, dropout=0.2):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.N_layers = N_layers\n",
        "\t\tself.embed = nn.Embedding(vocab_size, model_dim)\n",
        "\t\tself.pos_enc = PositionalEncoding(model_dim, max_seq_len, dropout)\n",
        "\t\tself.encoder_layers = nn.ModuleList(EncoderLayer(model_dim, num_heads, ff_dim, dropout)\n",
        "\t\t\t\t\t\t\t\t\tfor _ in range(N_layers))\n",
        "\t\tself.norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "\tdef forward(self, src, mask):\n",
        "\t\t\"\"\"\n",
        "\t\tsrc: [batch_size, seq_len]\n",
        "\t\tmask: [batch_size, 1, seq_len]\n",
        "\t\toutput: [batch_size, seq_len, model_dim]\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tx = self.embed(src)\n",
        "\t\tx = self.pos_enc(x)\n",
        "\t\tfor layer in self.encoder_layers:\n",
        "\t\t\tx = layer(x, mask)\n",
        "\t\treturn self.norm(x)\n",
        "\n",
        "Encoder(232, 512, 6, 8)(torch.LongTensor(32, 30).random_(0, 10), torch.rand(32, 1, 30)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbxaE2_G7_wZ",
        "outputId": "07c5ef01-cbf7-4cef-f685-0a25ea870075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 30, 512])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Decoder(nn.Module):\n",
        "\tdef __init__(self, vocab_size, model_dim, N_layers, num_heads, max_seq_len=144, ff_dim=1024, dropout=0.2):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.N_layers = N_layers\n",
        "\t\tself.embed = nn.Embedding(vocab_size, model_dim)\n",
        "\t\tself.pos_enc = PositionalEncoding(model_dim, max_seq_len, dropout)\n",
        "\t\tself.decoder_layers = nn.ModuleList(DecoderLayer(model_dim, num_heads, ff_dim, dropout)\n",
        "\t\t\t\t\t\t\t\t\tfor _ in range(N_layers))\n",
        "\t\tself.norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "\tdef forward(self, trg, enc_output, src_mask, trg_mask):\n",
        "\t\t\"\"\"\n",
        "\t\ttrg: [batch_size, seq_len]\n",
        "\t\tenc_output: [batch_size, seq_len, model_dim]\n",
        "\t\tsrc_mask: [batch_size, 1, seq_len]\n",
        "\t\ttrg_mask: [batch_size, 1, seq_len]\n",
        "\t\toutput: [batch_size, seq_len, model_dim]\n",
        "\t\t\"\"\"\n",
        "\t\tx = self.embed(trg)\n",
        "\t\tx = self.pos_enc(x)\n",
        "\t\tfor layer in self.decoder_layers:\n",
        "\t\t\tx = layer(x, enc_output, src_mask, trg_mask)\n",
        "\t\treturn self.norm(x)\n",
        "\n",
        "\n",
        "Decoder(232, 512, 6, 8)(torch.LongTensor(32, 30).random_(0, 10), torch.rand(32, 30, 512), torch.rand(32, 1, 30), torch.rand(32, 1, 30)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvtVAZSK7_wZ",
        "outputId": "77045344-2b30-41bd-85c6-3a617a4837da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 30, 232])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Transformer(nn.Module):\n",
        "\tdef __init__(self, src_vocab_size, trg_vocab_size, model_dim, N_layers, num_heads, max_seq_len=144, ff_dim=2048, dropout=0.2):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.encoder = Encoder(src_vocab_size, model_dim, N_layers, num_heads, max_seq_len, ff_dim, dropout)\n",
        "\t\tself.decoder = Decoder(trg_vocab_size, model_dim, N_layers, num_heads, max_seq_len, ff_dim, dropout)\n",
        "\t\tself.out = nn.Linear(model_dim, trg_vocab_size)\n",
        "\n",
        "\tdef forward(self, src, trg, src_mask=None, trg_mask=None):\n",
        "\t\t\"\"\"\n",
        "\t\tsrc: [batch_size, seq_len]\n",
        "\t\ttrg: [batch_size, seq_len]\n",
        "\t\tsrc_mask: [batch_size, 1, seq_len]\n",
        "\t\ttrg_mask [batch_size, 1, seq_len]\n",
        "\t\toutput: [batch_size, seq_len, vocab_size]\n",
        "\t\t\"\"\"\n",
        "\t\tenc_output = self.encoder(src, src_mask)\n",
        "\t\tdec_output = self.decoder(trg, enc_output, src_mask, trg_mask)\n",
        "\t\toutput = self.out(dec_output)\n",
        "\t\treturn output\n",
        "\n",
        "Transformer(232, 232, 512, 6, 8)(torch.LongTensor(32, 30).random_(0, 10), torch.LongTensor(32, 30).random_(0, 10),torch.rand(32, 1, 30),torch.rand(32, 1, 30)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoScjm1HsZ87"
      },
      "source": [
        "# V - Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1TsKyStI7_wa"
      },
      "outputs": [],
      "source": [
        "def generate_masks(src, trg):\n",
        "\tsrc_mask = (src != tokenizer.pad_token_id).unsqueeze(1)  # [batch_size, 1, src_len]\n",
        "\ttrg_mask = (trg != tokenizer.pad_token_id).unsqueeze(1)  # [batch_size, 1, trg_len]\n",
        "\tseq_len = trg.size(1)\n",
        "\tnopeak_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(trg.device)\n",
        "\ttrg_mask = trg_mask & (~nopeak_mask).unsqueeze(0)  # Combine padding and causal mask\n",
        "\treturn src_mask, trg_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "N4acodvO7_wa"
      },
      "outputs": [],
      "source": [
        "def get_lr(step_num, model_dim=512, warmup_steps=4000):\n",
        "\treturn model_dim ** (-0.5) * min(step_num ** (-0.5), step_num * warmup_steps ** (-1.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "CUlUY5lc7_wa"
      },
      "outputs": [],
      "source": [
        "SRC_VOCAB_SIZE = tokenizer.vocab_size\n",
        "TRG_VOCAB_SIZE = tokenizer.vocab_size\n",
        "MODEL_DIM = 512\n",
        "N_LAYERS = 6\n",
        "NUM_HEADS = 8\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Transformer(\n",
        "\tsrc_vocab_size=SRC_VOCAB_SIZE,\n",
        "\ttrg_vocab_size=TRG_VOCAB_SIZE,\n",
        "\tmodel_dim=MODEL_DIM,\n",
        "\tN_layers=N_LAYERS,\n",
        "\tnum_heads=NUM_HEADS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufED8KyAsfrk",
        "outputId": "89a60e43-b187-499a-dd89-ca541859ca1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (embed): Embedding(250054, 512)\n",
              "    (pos_enc): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (encoder_layers): ModuleList(\n",
              "      (0-5): 6 x EncoderLayer(\n",
              "        (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): MultiHeadAttention(\n",
              "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (ffn): FeedForward(\n",
              "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (dropout_1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout_2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embed): Embedding(250054, 512)\n",
              "    (pos_enc): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (decoder_layers): ModuleList(\n",
              "      (0-5): 6 x DecoderLayer(\n",
              "        (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm_3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout_1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout_2): Dropout(p=0.2, inplace=False)\n",
              "        (dropout_3): Dropout(p=0.2, inplace=False)\n",
              "        (attn_1): MultiHeadAttention(\n",
              "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (attn_2): MultiHeadAttention(\n",
              "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (ffn): FeedForward(\n",
              "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (out): Linear(in_features=512, out_features=250054, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "\tfor _, param in m.named_parameters():\n",
        "\t\tif param.dim() > 1:\n",
        "\t\t\tnn.init.xavier_uniform_(param.data)\n",
        "\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F57Wuf_syKs",
        "outputId": "14bbd32a-99b4-4adf-bafe-83e71db1c868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 428,473,542 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "\treturn sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "s2tcO4z77_wf"
      },
      "outputs": [],
      "source": [
        "src = batch['en_ids']\n",
        "trg = batch['vi_ids']\n",
        "src_mask, trg_mask = generate_masks(src, trg)\n",
        "output = model(src, trg, src_mask, trg_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP-5w5Mq7_wg",
        "outputId": "771ef60c-6447-4363-9f8e-dcedbea6b836"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([182222, 225228, 172370, 143265, 244996,  81288, 225353,  32492,  95782,\n",
              "         52813, 210280, 225027, 149617,   3643, 115520,  16277,  99576,  19704,\n",
              "         35067, 115520, 150028, 200847,  97937, 249910,   9544, 249910,   8030,\n",
              "        201780,  65130, 216548])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.argmax(output[0], dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "reHP3i7S7_wg"
      },
      "outputs": [],
      "source": [
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, vocab_size, smoothing=0.1, ignore_index=None):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.smoothing = smoothing\n",
        "        self.ignore_index = ignore_index\n",
        "        self.confidence = 1.0 - smoothing\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        \"\"\"\n",
        "        output: Tensor of shape [batch, seq_len, vocab_size] - Logits\n",
        "        target: Tensor of shape [batch, seq_len] - IDs target\n",
        "        \"\"\"\n",
        "        true_dist = torch.zeros_like(output)\n",
        "        true_dist.fill_(self.smoothing / (self.vocab_size - (1 if self.ignore_index is not None else 0)))\n",
        "        true_dist.scatter_(-1, target.unsqueeze(-1), self.confidence) # Dim = 2 (vocab dim)\n",
        "        if self.ignore_index is not None:\n",
        "            mask = (target == self.ignore_index)  # [batch, seq_len]\n",
        "            true_dist[mask] = 0\n",
        "\n",
        "        log_probs = torch.log_softmax(output, dim=-1)  # [batch, seq_len, vocab_size]\n",
        "        loss = -torch.sum(true_dist * log_probs, dim=-1)\n",
        "\n",
        "        if self.ignore_index is not None:\n",
        "            mask = (target != self.ignore_index).float()\n",
        "            loss = loss * mask\n",
        "            return torch.sum(loss) / torch.sum(mask)\n",
        "        return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vKV8ChTvuizM"
      },
      "outputs": [],
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "scaler = GradScaler('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "i54D9nW5s37S"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
        "criterion = LabelSmoothingLoss(vocab_size=tokenizer.vocab_size, smoothing=0.1, ignore_index=PAD_INDEX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33b1bNu57_wg",
        "outputId": "8c64970f-61af-4ce2-a30f-43f7a282b31f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(12.4315, grad_fn=<DivBackward0>)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion(output, trg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "68OaIdA87_wg"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self):\n",
        "        self.global_step = 0\n",
        "\n",
        "    def train_model(self, model, data_loader, optimizer, criterion, scaler, clip, device):\n",
        "        model.to(device).train()\n",
        "        epoch_loss = 0\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            self.global_step += 1\n",
        "            src = batch[\"en_ids\"].to(device)\n",
        "            trg = batch[\"vi_ids\"].to(device)\n",
        "            src_mask, trg_mask = generate_masks(src, trg)\n",
        "\n",
        "            # Forward\n",
        "            lr = get_lr(self.global_step, model_dim=512, warmup_steps=4000)\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group[\"lr\"] = lr\n",
        "\n",
        "            with autocast(\"cuda\"):\n",
        "                output = model(src, trg, src_mask, trg_mask)\n",
        "                loss = criterion(output, trg)\n",
        "            # Update\n",
        "            optimizer.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            if (i + 1) % 500 == 0:\n",
        "                    print(f\"Batch: {i + 1}/ {len(data_loader)}: Loss {epoch_loss / (i+1):.3f}\")\n",
        "            if (i + 1) % 2000 == 0:\n",
        "                    torch.save(model.state_dict(), \"/content/drive/MyDrive/model.pth\")\n",
        "            del src, trg, output, loss, batch\n",
        "            torch.cuda.empty_cache()\n",
        "        return epoch_loss / len(data_loader)\n",
        "\n",
        "    def evaluate_model(self, model, data_loader, criterion, device):\n",
        "        model.to(device).eval()\n",
        "        epoch_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(data_loader):\n",
        "                src = batch[\"en_ids\"].to(device)\n",
        "                trg = batch[\"vi_ids\"].to(device)\n",
        "                src_mask, trg_mask = generate_masks(src, trg)\n",
        "\n",
        "                with autocast('cuda'):\n",
        "                    output = model(src, trg, src_mask, trg_mask)  # turn off teacher forcing\n",
        "                    loss = criterion(output, trg)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "HHaL26v4wIie"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:25\"\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvgaYAT-tCf_",
        "outputId": "78080aee-3938-4a81-c978-63e9f5d1c91d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch: 500/ 12705: Loss 10.566\n",
            "Batch: 1000/ 12705: Loss 8.387\n",
            "Batch: 1500/ 12705: Loss 6.997\n",
            "Batch: 2000/ 12705: Loss 5.934\n",
            "Batch: 2500/ 12705: Loss 5.175\n",
            "Batch: 3000/ 12705: Loss 4.634\n",
            "Batch: 3500/ 12705: Loss 4.234\n",
            "Batch: 4000/ 12705: Loss 3.929\n",
            "Batch: 4500/ 12705: Loss 3.689\n",
            "Batch: 5000/ 12705: Loss 3.494\n",
            "Batch: 5500/ 12705: Loss 3.334\n",
            "Batch: 6000/ 12705: Loss 3.199\n",
            "Batch: 6500/ 12705: Loss 3.085\n",
            "Batch: 7000/ 12705: Loss 2.987\n",
            "Batch: 7500/ 12705: Loss 2.901\n",
            "Batch: 8000/ 12705: Loss 2.826\n",
            "Batch: 8500/ 12705: Loss 2.759\n",
            "Batch: 9000/ 12705: Loss 2.700\n",
            "Batch: 9500/ 12705: Loss 2.647\n",
            "Batch: 10000/ 12705: Loss 2.599\n",
            "Batch: 10500/ 12705: Loss 2.556\n",
            "Batch: 11000/ 12705: Loss 2.516\n",
            "Batch: 11500/ 12705: Loss 2.480\n",
            "Batch: 12000/ 12705: Loss 2.446\n",
            "Batch: 12500/ 12705: Loss 2.416\n",
            "\n",
            "\tTrain Loss:   2.404 | Train PPL:  11.066\n",
            "\tValid Loss:   1.703 | Valid PPL:   5.493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [1:11:37<00:00, 4297.64s/it]\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 1\n",
        "clip = 1.0\n",
        "trainer = Trainer()\n",
        "\n",
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "for epoch in tqdm.tqdm(range(n_epochs)):\n",
        "\ttrain_loss = trainer.train_model(\n",
        "\t\tmodel,\n",
        "\t\ttrain_dataloader,\n",
        "\t\toptimizer,\n",
        "\t\tcriterion,\n",
        "\t\tscaler,\n",
        "\t\tclip,\n",
        "\t\tDEVICE\n",
        "\t)\n",
        "\ttorch.save(model.state_dict(), \"/content/drive/MyDrive/model.pth\")\n",
        "\tprint(f\"\\n\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
        "\tvalid_loss = trainer.evaluate_model(\n",
        "\t\tmodel,\n",
        "\t\tvalid_dataloader,\n",
        "\t\tcriterion,\n",
        "\t\tDEVICE\n",
        "\t)\n",
        "\tprint(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
        "\tif valid_loss < best_valid_loss:\n",
        "\t\tbest_valid_loss = valid_loss\n",
        "\t\ttorch.save(model.state_dict(), \"/content/drive/MyDrive/model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GG6ln5Yownj"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vYhU6P7sri8W"
      },
      "outputs": [],
      "source": [
        "SRC_VOCAB_SIZE = tokenizer.vocab_size\n",
        "TRG_VOCAB_SIZE = tokenizer.vocab_size\n",
        "MODEL_DIM = 512\n",
        "N_LAYERS = 6\n",
        "NUM_HEADS = 8\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# DEVICE = torch.device('cpu')\n",
        "\n",
        "model = Transformer(\n",
        "\tsrc_vocab_size=SRC_VOCAB_SIZE,\n",
        "\ttrg_vocab_size=TRG_VOCAB_SIZE,\n",
        "\tmodel_dim=MODEL_DIM,\n",
        "\tN_layers=N_LAYERS,\n",
        "\tnum_heads=NUM_HEADS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbjCvKW_tJeD",
        "outputId": "dba414a8-dff6-4174-ce8d-693d3e754ba4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lorX4kWG7_wh",
        "outputId": "2be267af-296d-4ccf-c6a8-b2344d3b788a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (embed): Embedding(250054, 512)\n",
              "    (pos_enc): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (encoder_layers): ModuleList(\n",
              "      (0-5): 6 x EncoderLayer(\n",
              "        (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): MultiHeadAttention(\n",
              "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (ffn): FeedForward(\n",
              "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (dropout_1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout_2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embed): Embedding(250054, 512)\n",
              "    (pos_enc): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (decoder_layers): ModuleList(\n",
              "      (0-5): 6 x DecoderLayer(\n",
              "        (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm_3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout_1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout_2): Dropout(p=0.2, inplace=False)\n",
              "        (dropout_3): Dropout(p=0.2, inplace=False)\n",
              "        (attn_1): MultiHeadAttention(\n",
              "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (attn_2): MultiHeadAttention(\n",
              "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (ffn): FeedForward(\n",
              "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (out): Linear(in_features=512, out_features=250054, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ier0VG2h7_wh",
        "outputId": "5d8cf4d1-82f5-4ece-e9df-df1c9d0098be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.707 | Test PPL:   5.511 |\n"
          ]
        }
      ],
      "source": [
        "test_loss = trainer.evaluate_model(model, test_dataloader, criterion, DEVICE)\n",
        "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPAbq_JZr-nQ",
        "outputId": "ec0ad28e-862f-4f93-9aee-cf226f0d88d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation: \n"
          ]
        }
      ],
      "source": [
        "def beam_search_decode(model, src, src_mask, tokenizer, beam_width=5, max_len=144, length_penalty=1.0):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    initial_trg = torch.tensor([[tokenizer.bos_token_id]], device=device)\n",
        "    beams = [(initial_trg, 0.0)]  # [(seq, log-prob)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step in range(max_len):\n",
        "            new_beams = []\n",
        "            for trg, score in beams:\n",
        "                # Create causal mask for target (only look at previous token)\n",
        "                trg_mask = torch.triu(torch.ones(trg.size(1), trg.size(1)), diagonal=1).bool().to(device)\n",
        "                trg_mask = (~trg_mask).unsqueeze(0)  # [seq_len, seq_len]\n",
        "\n",
        "                # Predict next word\n",
        "                output = model(src, trg, src_mask, trg_mask)\n",
        "                logits = output[:, -1, :]  # Final word logits [batch=1, vocab_size]\n",
        "                probs = torch.log_softmax(logits, dim=-1)  # Log-probabilities\n",
        "                top_k_probs, top_k_ids = probs.topk(beam_width, dim=-1)  # Get top-k\n",
        "\n",
        "                # Expand each beam\n",
        "                for prob, token_id in zip(top_k_probs[0], top_k_ids[0]):\n",
        "                    new_score = score + prob.item()\n",
        "                    new_trg = torch.cat([trg, token_id.unsqueeze(0).unsqueeze(0)], dim=1)\n",
        "                    # Apply penalty\n",
        "                    adjusted_score = new_score / ((new_trg.size(1) / 5.0) ** length_penalty)\n",
        "                    new_beams.append((new_trg, adjusted_score))  # Keep original score to sort accurately\n",
        "\n",
        "            # Sort and keep top beam_width beams\n",
        "            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "            # Check if all beams have finished (got </s>)\n",
        "            all_done = all(tokenizer.eos_token_id in beam[0][0] for beam in beams)\n",
        "            if all_done:\n",
        "                break\n",
        "\n",
        "    # Choose beam has highest score\n",
        "    best_beam = max(beams, key=lambda x: x[1])\n",
        "    return best_beam[0]  # Return best sequence [1, seq_len]\n",
        "\n",
        "def translate_sentence(sentence, model, tokenizer, beam_width=5, max_len=128):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize src\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", max_length=max_len, truncation=True, padding=\"max_length\")\n",
        "    src = inputs[\"input_ids\"].to(device)\n",
        "    src_mask = (src != tokenizer.pad_token_id).unsqueeze(1)\n",
        "\n",
        "    # Call beam\n",
        "    translated_tokens = beam_search_decode(model, src, src_mask, tokenizer, beam_width, max_len)\n",
        "\n",
        "    # Decode\n",
        "    translation = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
        "    return translation\n",
        "\n",
        "# Thử nghiệm dịch\n",
        "sentence = \"The pharmacy is on Fresno Street\"\n",
        "translation = translate_sentence(sentence, model, tokenizer, beam_width=5)\n",
        "print(f\"Translation: {translation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyJzV1SRHtGn",
        "outputId": "53a2dae0-cacd-4cb4-94b1-0cac360673fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.bos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2Bv7xM6io12C",
        "outputId": "330ad3e6-ff49-479a-c0fa-4accce728e64"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate_sentence(\"Who am I?\", model, tokenizer, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BJwyvFppuTc4",
        "outputId": "e929614c-5e15-4a26-ed56-744934aab66f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate_sentence(\"She sells seashell on the seashore\", model, tokenizer, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "3f25bbacd2b54c08a6d598ce770633b7",
            "f6fbe83fdf0b49088fecab66fc7c372b",
            "99899da7b392423993926d6bdc5e3f7c",
            "49172d5c010e4e268edac2bb5a281dfc",
            "b22e9e2a7f42416eae14a9e529ba7b78",
            "eaedd11007a142bfb051bb63c5f25f8f",
            "26abf9e089e243fe92e506a81a057302",
            "c8e3ff35a46544f9977222100bf17a52",
            "6378f998da6442d794ee20d0eb157865",
            "221d1b92473f4b7e95e54db9eddaa5eb",
            "012b16f313924ec199058d6ff6d8ff86",
            "a4ea978e79a449fc9e4e9a95f9018120",
            "f6e9efb8e74a45088ac76fa585d997f6",
            "8ac3dcece0ad4ee8a01cdc6b4888df41",
            "f997e6a83c8c4324a6397f92cf3e4a72",
            "1caec63f81324877bb54878fafccf45d",
            "036bd12ac0c2442089629e71f9d7a145",
            "a125f01514104a6399013b26f4502ed1",
            "67f8ee55db5045d4972f29da6ebe99f0",
            "206755f2962c4191a97d8c9bac9b5228",
            "df226a4d8edb41139a189acf434f4e94",
            "e71cbb98536a4e8899c76e9faa84a565",
            "7c5dbf191c9d4bd0a0b66b535a8074c0",
            "1b09ac7089b340f09508d979b4cb87c0",
            "77cfdedf24744975996524a54bfd4f04",
            "055fdfb2a4064ee8aecf7d74199f258b",
            "919a00465fe54c1685d73fa6bb528f9b",
            "43c3816efe0c4a5496b83e5347eec251",
            "3cab2e19c0fd42afb230c93d092423fa",
            "4f3257b7475647dda403fbec41d7c61e",
            "44745b0451134258ae7577acf70591bc",
            "85d260e9336d46da920d945ba813b01a",
            "f3257fc67ce345f7a823312c161649b3"
          ]
        },
        "id": "baVYna3Nvz7a",
        "outputId": "2f5afeed-f4a5-412e-9d74-4ea92d750923"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f25bbacd2b54c08a6d598ce770633b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4ea978e79a449fc9e4e9a95f9018120",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c5dbf191c9d4bd0a0b66b535a8074c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bleu = evaluate.load(\"bleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Xat3uMCVx0Nx"
      },
      "outputs": [],
      "source": [
        "# dataset = datasets.load_dataset(\"harouzie/vi_en-translation\")\n",
        "test_data= dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASMXknsZzyjw"
      },
      "outputs": [],
      "source": [
        "translations = [\n",
        "\ttranslate_sentence(\n",
        "\t\texample[\"English\"],\n",
        "\t\tmodel,\n",
        "\t\ttokenizer\n",
        "\t)\n",
        "\tfor example in test_data\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxSbX2jrzoLF"
      },
      "outputs": [],
      "source": [
        "predictions = [translation for translation in translations]\n",
        "\n",
        "references = [[example[\"vi_i\"]] for example in test_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ6GgOLF4j57"
      },
      "outputs": [],
      "source": [
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2m7WrsZ4mIO"
      },
      "outputs": [],
      "source": [
        "references[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUjuBsxpzvBf"
      },
      "outputs": [],
      "source": [
        "results = bleu.compute(\n",
        "\tpredictions=predictions, references=references\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63AC_S1x4cHW"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sz0AuGN4hjh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "012b16f313924ec199058d6ff6d8ff86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "036bd12ac0c2442089629e71f9d7a145": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "055fdfb2a4064ee8aecf7d74199f258b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85d260e9336d46da920d945ba813b01a",
            "placeholder": "​",
            "style": "IPY_MODEL_f3257fc67ce345f7a823312c161649b3",
            "value": " 3.34k/3.34k [00:00&lt;00:00, 235kB/s]"
          }
        },
        "136dd050721246c4bb584d83c4125210": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b09ac7089b340f09508d979b4cb87c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c3816efe0c4a5496b83e5347eec251",
            "placeholder": "​",
            "style": "IPY_MODEL_3cab2e19c0fd42afb230c93d092423fa",
            "value": "Downloading extra modules: 100%"
          }
        },
        "1caec63f81324877bb54878fafccf45d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "206755f2962c4191a97d8c9bac9b5228": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "221d1b92473f4b7e95e54db9eddaa5eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26abf9e089e243fe92e506a81a057302": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a70df98f70f4f51aeb861c1ca3e3243": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aa32e6fcd284126bd8e4955fab735a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c3a7061dd545218cf5e2805366213f",
            "max": 25409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83787ea2b309464d9afc0257079573e8",
            "value": 25409
          }
        },
        "3cab2e19c0fd42afb230c93d092423fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f25bbacd2b54c08a6d598ce770633b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6fbe83fdf0b49088fecab66fc7c372b",
              "IPY_MODEL_99899da7b392423993926d6bdc5e3f7c",
              "IPY_MODEL_49172d5c010e4e268edac2bb5a281dfc"
            ],
            "layout": "IPY_MODEL_b22e9e2a7f42416eae14a9e529ba7b78"
          }
        },
        "42824743e3e5449b8885a85ab17e29a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43c3816efe0c4a5496b83e5347eec251": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44745b0451134258ae7577acf70591bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49172d5c010e4e268edac2bb5a281dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_221d1b92473f4b7e95e54db9eddaa5eb",
            "placeholder": "​",
            "style": "IPY_MODEL_012b16f313924ec199058d6ff6d8ff86",
            "value": " 5.94k/5.94k [00:00&lt;00:00, 585kB/s]"
          }
        },
        "4f3257b7475647dda403fbec41d7c61e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62ce97c2b1df444a84712ad88caf8744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abdd3e9d73684da788ba25a56effe28f",
            "placeholder": "​",
            "style": "IPY_MODEL_2a70df98f70f4f51aeb861c1ca3e3243",
            "value": " 25409/25409 [00:20&lt;00:00, 2182.12 examples/s]"
          }
        },
        "6378f998da6442d794ee20d0eb157865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67f8ee55db5045d4972f29da6ebe99f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77cfdedf24744975996524a54bfd4f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f3257b7475647dda403fbec41d7c61e",
            "max": 3344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44745b0451134258ae7577acf70591bc",
            "value": 3344
          }
        },
        "7a97c9e21de8469097cf9151dee05151": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c84cf45f82394072a7a24dfa4cf48c81",
              "IPY_MODEL_3aa32e6fcd284126bd8e4955fab735a3",
              "IPY_MODEL_62ce97c2b1df444a84712ad88caf8744"
            ],
            "layout": "IPY_MODEL_a2fbf9bc93e649de8339dcf9c6daebb2"
          }
        },
        "7c5dbf191c9d4bd0a0b66b535a8074c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b09ac7089b340f09508d979b4cb87c0",
              "IPY_MODEL_77cfdedf24744975996524a54bfd4f04",
              "IPY_MODEL_055fdfb2a4064ee8aecf7d74199f258b"
            ],
            "layout": "IPY_MODEL_919a00465fe54c1685d73fa6bb528f9b"
          }
        },
        "83787ea2b309464d9afc0257079573e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85d260e9336d46da920d945ba813b01a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ac3dcece0ad4ee8a01cdc6b4888df41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67f8ee55db5045d4972f29da6ebe99f0",
            "max": 1554,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_206755f2962c4191a97d8c9bac9b5228",
            "value": 1554
          }
        },
        "919a00465fe54c1685d73fa6bb528f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99899da7b392423993926d6bdc5e3f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e3ff35a46544f9977222100bf17a52",
            "max": 5937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6378f998da6442d794ee20d0eb157865",
            "value": 5937
          }
        },
        "a125f01514104a6399013b26f4502ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2fbf9bc93e649de8339dcf9c6daebb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ea978e79a449fc9e4e9a95f9018120": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6e9efb8e74a45088ac76fa585d997f6",
              "IPY_MODEL_8ac3dcece0ad4ee8a01cdc6b4888df41",
              "IPY_MODEL_f997e6a83c8c4324a6397f92cf3e4a72"
            ],
            "layout": "IPY_MODEL_1caec63f81324877bb54878fafccf45d"
          }
        },
        "abdd3e9d73684da788ba25a56effe28f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b22e9e2a7f42416eae14a9e529ba7b78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c84cf45f82394072a7a24dfa4cf48c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_136dd050721246c4bb584d83c4125210",
            "placeholder": "​",
            "style": "IPY_MODEL_42824743e3e5449b8885a85ab17e29a5",
            "value": "Map: 100%"
          }
        },
        "c8e3ff35a46544f9977222100bf17a52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df226a4d8edb41139a189acf434f4e94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c3a7061dd545218cf5e2805366213f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e71cbb98536a4e8899c76e9faa84a565": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaedd11007a142bfb051bb63c5f25f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3257fc67ce345f7a823312c161649b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6e9efb8e74a45088ac76fa585d997f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_036bd12ac0c2442089629e71f9d7a145",
            "placeholder": "​",
            "style": "IPY_MODEL_a125f01514104a6399013b26f4502ed1",
            "value": "Downloading extra modules: "
          }
        },
        "f6fbe83fdf0b49088fecab66fc7c372b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaedd11007a142bfb051bb63c5f25f8f",
            "placeholder": "​",
            "style": "IPY_MODEL_26abf9e089e243fe92e506a81a057302",
            "value": "Downloading builder script: 100%"
          }
        },
        "f997e6a83c8c4324a6397f92cf3e4a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df226a4d8edb41139a189acf434f4e94",
            "placeholder": "​",
            "style": "IPY_MODEL_e71cbb98536a4e8899c76e9faa84a565",
            "value": " 4.07k/? [00:00&lt;00:00, 330kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
