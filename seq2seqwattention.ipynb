{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pprint import pprint","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:47:56.236098Z","iopub.execute_input":"2025-02-15T17:47:56.236485Z","iopub.status.idle":"2025-02-15T17:47:56.240239Z","shell.execute_reply.started":"2025-02-15T17:47:56.236457Z","shell.execute_reply":"2025-02-15T17:47:56.239261Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# I - Data preprocessing","metadata":{}},{"cell_type":"markdown","source":"## I.1 - Download dataset","metadata":{}},{"cell_type":"code","source":"# ! pip install datasets","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:47:56.241523Z","iopub.execute_input":"2025-02-15T17:47:56.241809Z","iopub.status.idle":"2025-02-15T17:47:56.257117Z","shell.execute_reply.started":"2025-02-15T17:47:56.241789Z","shell.execute_reply":"2025-02-15T17:47:56.256449Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:47:56.258994Z","iopub.execute_input":"2025-02-15T17:47:56.259231Z","iopub.status.idle":"2025-02-15T17:47:58.072050Z","shell.execute_reply.started":"2025-02-15T17:47:56.259199Z","shell.execute_reply":"2025-02-15T17:47:58.071388Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_name = 'ncduy/mt-en-vi'\ndata = load_dataset(data_name)","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:47:58.073272Z","iopub.execute_input":"2025-02-15T17:47:58.073818Z","iopub.status.idle":"2025-02-15T17:48:17.795116Z","shell.execute_reply.started":"2025-02-15T17:47:58.073786Z","shell.execute_reply":"2025-02-15T17:48:17.794430Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ab59fd2f435413493b5d53fb41a153b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.csv:   0%|          | 0.00/597M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f41c88e725dd45c3806639915e8607ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"valid.csv:   0%|          | 0.00/2.45M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b841b694d57f4e148f2ebbb099913988"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.csv:   0%|          | 0.00/2.43M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b421ffc528544e1e943934a0c2d4c1c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2884451 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8846878b35ad4998baffb1960c4b935e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11316 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb57afeb3cf947b2ae5fd92d0b89cbb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11225 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf9288d696b94473b4e5d0879986140c"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"sample_size = 100000\ntrain_data = data['train'].shuffle(seed=42).select(range(sample_size))\nvalidation_data = data['validation'].shuffle(seed=42).select(range(int(0.1*sample_size)))\ntest_data = data['test'].shuffle(seed=42).select(range(int(0.1*sample_size)))","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:17.795925Z","iopub.execute_input":"2025-02-15T17:48:17.796298Z","iopub.status.idle":"2025-02-15T17:48:18.607606Z","shell.execute_reply.started":"2025-02-15T17:48:17.796266Z","shell.execute_reply":"2025-02-15T17:48:18.606900Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(train_data.shape)\npprint(train_data[0])","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:18.608470Z","iopub.execute_input":"2025-02-15T17:48:18.608767Z","iopub.status.idle":"2025-02-15T17:48:18.615142Z","shell.execute_reply.started":"2025-02-15T17:48:18.608738Z","shell.execute_reply":"2025-02-15T17:48:18.614372Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(100000, 3)\n{'en': '\"education and leading me to providing service to the Republic.\"',\n 'source': 'OpenSubtitles v2018',\n 'vi': '\"nơi giáo dục và dìu dắt tôi để tôi có thể phụng sự nền Cộng Hòa\"'}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## I.2 - Process data using SentencePiece","metadata":{}},{"cell_type":"code","source":"import sentencepiece as spm\nimport os","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:18.615878Z","iopub.execute_input":"2025-02-15T17:48:18.616064Z","iopub.status.idle":"2025-02-15T17:48:18.770905Z","shell.execute_reply.started":"2025-02-15T17:48:18.616048Z","shell.execute_reply":"2025-02-15T17:48:18.770174Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Save data into files\ndef save_to_file(data, filename):\n    with open(filename+'.en', 'w', encoding='utf-8') as f_en, open(filename+'.vi', 'w', encoding='utf-8') as f_vi:\n        for sample in data:\n            f_en.write(sample['en'] + '\\n')\n            f_vi.write(sample['vi'] + '\\n')","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:18.773555Z","iopub.execute_input":"2025-02-15T17:48:18.773786Z","iopub.status.idle":"2025-02-15T17:48:18.777987Z","shell.execute_reply.started":"2025-02-15T17:48:18.773767Z","shell.execute_reply":"2025-02-15T17:48:18.777237Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"save_to_file(train_data, '/kaggle/working/train')\nsave_to_file(validation_data, '/kaggle/working/validation')\nsave_to_file(test_data, '/kaggle/working/test')","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:18.779470Z","iopub.execute_input":"2025-02-15T17:48:18.779691Z","iopub.status.idle":"2025-02-15T17:48:27.878717Z","shell.execute_reply.started":"2025-02-15T17:48:18.779672Z","shell.execute_reply":"2025-02-15T17:48:27.877925Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Training SentencePiece\ndef training_sentencepiece(trainfile, prefix, vocab_size=11140, type='bpe'):\n    spm.SentencePieceTrainer.Train(\n        input=trainfile+'.en',\n        model_prefix=prefix+'_en',\n        vocab_size=vocab_size,\n        model_type=type\n    )\n    spm.SentencePieceTrainer.Train(\n        input=trainfile+'.vi',\n        model_prefix=prefix+'_vi',\n        vocab_size=vocab_size,\n        model_type=type\n    )\n    \n    # Load trained tokenizer\n    sp_en = spm.SentencePieceProcessor(model_file=prefix+\"_en.model\")\n    sp_vi = spm.SentencePieceProcessor(model_file=prefix+\"_vi.model\")\n    \n    return sp_en, sp_vi","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:27.879569Z","iopub.execute_input":"2025-02-15T17:48:27.879859Z","iopub.status.idle":"2025-02-15T17:48:27.884892Z","shell.execute_reply.started":"2025-02-15T17:48:27.879825Z","shell.execute_reply":"2025-02-15T17:48:27.883990Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"trainfile = '/kaggle/working/train'\nprefix = '/kaggle/working/spm'\nsp_en, sp_vi = training_sentencepiece(trainfile, prefix)","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:27.885831Z","iopub.execute_input":"2025-02-15T17:48:27.886108Z","iopub.status.idle":"2025-02-15T17:48:41.221619Z","shell.execute_reply.started":"2025-02-15T17:48:27.886086Z","shell.execute_reply":"2025-02-15T17:48:41.220625Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"example_en = \"education and leading me to providing service to the Republic.\"\nexample_vi = \"Tôi yêu đại bàng!\"\n\nprint(sp_en.encode(example_en, out_type=str))\nprint(sp_vi.encode(example_vi, out_type=str))","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:41.222682Z","iopub.execute_input":"2025-02-15T17:48:41.222942Z","iopub.status.idle":"2025-02-15T17:48:41.235719Z","shell.execute_reply.started":"2025-02-15T17:48:41.222921Z","shell.execute_reply":"2025-02-15T17:48:41.234789Z"},"trusted":true},"outputs":[{"name":"stdout","text":"['▁education', '▁and', '▁leading', '▁me', '▁to', '▁providing', '▁service', '▁to', '▁the', '▁Republic', '.']\n['▁Tôi', '▁yêu', '▁đại', '▁bàng', '!']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## I.3 - Convert data to Tensor","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:41.236654Z","iopub.execute_input":"2025-02-15T17:48:41.236989Z","iopub.status.idle":"2025-02-15T17:48:44.025419Z","shell.execute_reply.started":"2025-02-15T17:48:41.236958Z","shell.execute_reply":"2025-02-15T17:48:44.024718Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class TranslationDataset(Dataset):\n    def __init__(self, src_texts, tgt_texts, src_tokenizer, tgt_tokenizer, max_length=128):\n        self.src_texts = src_texts\n        self.tgt_texts = tgt_texts\n        self.src_tokenizer = src_tokenizer\n        self.tgt_tokenizer = tgt_tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.src_texts)\n\n    def __getitem__(self, idx):\n        # Tokenize input (source - English)\n        src_ids = self.src_tokenizer.encode(self.src_texts[idx])[:self.max_length - 1]  \n        src_ids.append(self.src_tokenizer.eos_id())  # Thêm <EOS>\n\n        # Tokennize output (target - Vietnamese)\n        tgt_ids = self.tgt_tokenizer.encode(self.tgt_texts[idx])[:self.max_length - 2]  \n        tgt_ids = [self.tgt_tokenizer.bos_id()] + tgt_ids + [self.tgt_tokenizer.eos_id()]  # Add <SOS> and <EOS>\n\n        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n\n\n# Padding batch\ndef collate_fn(batch):\n    src_batch, tgt_batch = zip(*batch)\n    \n    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n    tgt_batch = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n\n    return {\"src\": src_batch, \"tgt\": tgt_batch}","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:44.026302Z","iopub.execute_input":"2025-02-15T17:48:44.026564Z","iopub.status.idle":"2025-02-15T17:48:44.032919Z","shell.execute_reply.started":"2025-02-15T17:48:44.026543Z","shell.execute_reply":"2025-02-15T17:48:44.032044Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_src_texts = train_data['en']\ntrain_tgt_texts = train_data['vi']\n\ntrain_dataset = TranslationDataset(train_src_texts, train_tgt_texts, sp_en, sp_vi)","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:44.033838Z","iopub.execute_input":"2025-02-15T17:48:44.034110Z","iopub.status.idle":"2025-02-15T17:48:45.575596Z","shell.execute_reply.started":"2025-02-15T17:48:44.034089Z","shell.execute_reply":"2025-02-15T17:48:45.574453Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"val_src_texts = validation_data['en']\nval_tgt_texts = validation_data['vi']\n\nval_dataset = TranslationDataset(val_src_texts, val_tgt_texts, sp_en, sp_vi)","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:45.576603Z","iopub.execute_input":"2025-02-15T17:48:45.576853Z","iopub.status.idle":"2025-02-15T17:48:45.681864Z","shell.execute_reply.started":"2025-02-15T17:48:45.576831Z","shell.execute_reply":"2025-02-15T17:48:45.681121Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# DataLoader\nbatch_size = 32\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:45.682717Z","iopub.execute_input":"2025-02-15T17:48:45.682975Z","iopub.status.idle":"2025-02-15T17:48:45.687756Z","shell.execute_reply.started":"2025-02-15T17:48:45.682952Z","shell.execute_reply":"2025-02-15T17:48:45.686778Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"batch = next(iter(train_dataloader))\nprint(batch['src'].shape)\npprint(batch['src'])","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:45.688699Z","iopub.execute_input":"2025-02-15T17:48:45.689017Z","iopub.status.idle":"2025-02-15T17:48:45.783018Z","shell.execute_reply.started":"2025-02-15T17:48:45.688985Z","shell.execute_reply":"2025-02-15T17:48:45.782229Z"},"trusted":true},"outputs":[{"name":"stdout","text":"torch.Size([32, 64])\ntensor([[ 2598,   295,   225,  ...,     0,     0,     0],\n        [  286,   884,  1094,  ...,     0,     0,     0],\n        [   36,   184, 11000,  ...,     0,     0,     0],\n        ...,\n        [  488, 11000, 10982,  ...,     0,     0,     0],\n        [  201,  1007, 10995,  ...,     0,     0,     0],\n        [  385,     8,    49,  ...,     0,     0,     0]])\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# II - Build model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:45.783870Z","iopub.execute_input":"2025-02-15T17:48:45.784189Z","iopub.status.idle":"2025-02-15T17:48:45.788073Z","shell.execute_reply.started":"2025-02-15T17:48:45.784160Z","shell.execute_reply":"2025-02-15T17:48:45.787150Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hidden_dim, num_layers, dropout=0.3, pad_idx=0):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n        self.rnn = nn.GRU(emb_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, src):\n        embedded = self.embedding(src)\n        embedded = self.dropout(embedded)\n        output, hidden = self.rnn(embedded)\n        return output, hidden\n        ","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:45.788900Z","iopub.execute_input":"2025-02-15T17:48:45.789604Z","iopub.status.idle":"2025-02-15T17:48:45.800712Z","shell.execute_reply.started":"2025-02-15T17:48:45.789564Z","shell.execute_reply":"2025-02-15T17:48:45.799890Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Luong Attention\nclass Attention(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        self.attn = nn.Linear(hidden_dim, hidden_dim, bias=False)\n        \n    def forward(self, hidden, encoder_output):\n        \"\"\"\n        hidden: (1, batch, hidden_dim) - decoder hidden state \n        encoder_output: (batch, seq_len, hidden_dim) - encoder output\n        \"\"\"\n        hidden = hidden[-1].unsqueeze(0)  # (batch, 1, hidden_dim)\n        \n        # Compute attention scores\n        scores = torch.matmul(self.attn(hidden).transpose(0, 1), encoder_output.permute(0, 2, 1))\n        attn_weights = torch.softmax(scores, dim=-1)  # (batch, 1, seq_len)\n        \n        # Get context vector\n        context = torch.matmul(attn_weights, encoder_output)  # (batch, 1, hidden_dim)\n        # print(context.size())\n        return context.squeeze(1), attn_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:48:45.801610Z","iopub.execute_input":"2025-02-15T17:48:45.801920Z","iopub.status.idle":"2025-02-15T17:48:45.816656Z","shell.execute_reply.started":"2025-02-15T17:48:45.801888Z","shell.execute_reply":"2025-02-15T17:48:45.815806Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hidden_dim, num_layers, dropout, attention, pad_idx=0):\n        super().__init__()\n        self.output_dim = output_dim\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n        self.rnn = nn.GRU(emb_dim + hidden_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.attention = attention\n\n    def forward(self, input, hidden, encoder_output):\n        \"\"\"\n        input: (batch,)\n        hidden: (1, batch, hidden_dim)\n        encoder_output: (batch, seq_len, hidden_dim)\n        \"\"\"\n        input = input.unsqueeze(0)  # (1, batch)\n        embedded = self.dropout(self.embedding(input))  # (1, batch, emb_dim)\n        \n        # Get context vector from attention\n        context, attn_weights = self.attention(hidden, encoder_output)  # (batch, hidden_dim), (batch, 1, seq_len)\n\n        # Combine context vector with input\n        rnn_input = torch.cat((embedded, context.unsqueeze(0)), dim=2)  # (1, batch, emb_dim + hidden_dim)\n        \n        output, hidden = self.rnn(rnn_input.permute(1, 0, 2), hidden)  # output: (batch, 1, hidden_dim)\n        \n        # Predict next word\n        prediction = self.fc_out(torch.cat((output.squeeze(1), context), dim=1))  # (batch, output_dim)\n        return prediction, hidden, attn_weights\n","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:45.817539Z","iopub.execute_input":"2025-02-15T17:48:45.817846Z","iopub.status.idle":"2025-02-15T17:48:45.828738Z","shell.execute_reply.started":"2025-02-15T17:48:45.817817Z","shell.execute_reply":"2025-02-15T17:48:45.827917Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import random\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        \"\"\"\n        src: (batch, seq_len)\n        trg: (batch, seq_len)\n        \"\"\"\n        batch_size = src.shape[0]\n        trg_len = trg.shape[1]\n        trg_vocab_size = self.decoder.output_dim\n        \n        # outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n\n        # Encode input\n        encoder_output, hidden = self.encoder(src)\n\n        # First token <SOS>\n        input = trg[:, 0]\n\n        for t in range(1, trg_len):\n            output, hidden, _ = self.decoder(input, hidden, encoder_output)\n            outputs[t] = output\n\n            # Teacher forcing\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n\n            input = trg[:, t] if teacher_force else top1\n\n        return outputs\n","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:45.831986Z","iopub.execute_input":"2025-02-15T17:48:45.832256Z","iopub.status.idle":"2025-02-15T17:48:45.845253Z","shell.execute_reply.started":"2025-02-15T17:48:45.832238Z","shell.execute_reply":"2025-02-15T17:48:45.844590Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Hyperparams\nINPUT_DIM = len(sp_en)\nOUTPUT_DIM = len(sp_vi)\nEMB_DIM = 256\nHIDDEN_DIM = 512\nNUM_LAYERS = 2\nDROPOUT = 0.3\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Init Encoder & Decoder \nattention = Attention(HIDDEN_DIM)\nencoder = Encoder(INPUT_DIM, EMB_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT)\ndecoder = Decoder(OUTPUT_DIM, EMB_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT, attention)\n\n# Init Seq2Seq\nmodel = Seq2Seq(encoder, decoder, DEVICE)\n","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:45.846447Z","iopub.execute_input":"2025-02-15T17:48:45.846700Z","iopub.status.idle":"2025-02-15T17:48:46.113851Z","shell.execute_reply.started":"2025-02-15T17:48:45.846679Z","shell.execute_reply":"2025-02-15T17:48:46.113115Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# III - Train and Evaluate model","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn as nn\nfrom tqdm import tqdm\n\n\nLEARNING_RATE = 0.001\nPAD_IDX = 0\n\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)  \noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:48:46.114658Z","iopub.execute_input":"2025-02-15T17:48:46.114954Z","iopub.status.idle":"2025-02-15T17:48:47.834670Z","shell.execute_reply.started":"2025-02-15T17:48:46.114898Z","shell.execute_reply":"2025-02-15T17:48:47.833687Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nmy_secret = user_secrets.get_secret(\"wandb-api\")\nwandb.login(key=my_secret)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:48:47.835616Z","iopub.execute_input":"2025-02-15T17:48:47.836163Z","iopub.status.idle":"2025-02-15T17:48:56.011451Z","shell.execute_reply.started":"2025-02-15T17:48:47.836128Z","shell.execute_reply":"2025-02-15T17:48:56.010770Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlongluv1605\u001b[0m (\u001b[33mlongluv1605-institute-for-artificial-intelligence\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"import random\nrandom.seed(42)\n\ndef train(model, iterator, optimizer, criterion, clip, teacher_forcing_ratio=0.5):\n    model.train()\n    epoch_loss = 0\n    model.to(DEVICE)\n    for batch in tqdm(iterator, desc=f'Training: '):\n        src, trg = batch['src'], batch['tgt']\n        src, trg = src.to(DEVICE), trg.to(DEVICE)\n        \n        optimizer.zero_grad()\n\n        output = model(src, trg, teacher_forcing_ratio)\n\n        output_dim = output.shape[-1]\n        output = output[1:].reshape(-1, output_dim)  # [batch_size * trg_len, vocab_size]\n        trg = trg[:, 1:].reshape(-1)  # [batch_size * trg_len]\n\n        loss = criterion(output, trg)\n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n\n        optimizer.step()\n        epoch_loss += loss.item()\n\n    return epoch_loss / len(iterator)\n","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:56.012313Z","iopub.execute_input":"2025-02-15T17:48:56.012895Z","iopub.status.idle":"2025-02-15T17:48:56.018332Z","shell.execute_reply.started":"2025-02-15T17:48:56.012860Z","shell.execute_reply":"2025-02-15T17:48:56.017650Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def evaluate(model, iterator, criterion):\n    model.eval()\n    epoch_loss = 0\n\n    with torch.no_grad():\n        for src, trg in tqdm(iterator, desc='Evaluating: '):\n            src, trg = batch['src'], batch['tgt']\n            src, trg = src.to(DEVICE), trg.to(DEVICE)\n            \n            output = model(src, trg, teacher_forcing_ratio=0)\n\n            output_dim = output.shape[-1]\n            output = output[1:].reshape(-1, output_dim)\n            trg = trg[:, 1:].reshape(-1)\n\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n    print()\n    return epoch_loss / len(iterator)\n","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:56.019393Z","iopub.execute_input":"2025-02-15T17:48:56.019695Z","iopub.status.idle":"2025-02-15T17:48:56.033726Z","shell.execute_reply.started":"2025-02-15T17:48:56.019654Z","shell.execute_reply":"2025-02-15T17:48:56.032930Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:56.034428Z","iopub.execute_input":"2025-02-15T17:48:56.034623Z","iopub.status.idle":"2025-02-15T17:48:56.044986Z","shell.execute_reply.started":"2025-02-15T17:48:56.034606Z","shell.execute_reply":"2025-02-15T17:48:56.044126Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"N_EPOCHS = 20\nCLIP = 5  # Max gradient norm\n\ntrain_losses = []\nval_losses = []\n\nfor epoch in range(N_EPOCHS):\n    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n    valid_loss = evaluate(model, val_dataloader, criterion)\n\n    best_loss = float('inf')\n    \n    print(f'Epoch {epoch+1}:')\n    print(f'  Train Loss: {train_loss:.3f}')\n    print(f'  Valid Loss: {valid_loss:.3f}')\n\n    if train_loss < best_loss:\n        best_loss = train_loss\n        torch.save(model.state_dict(), '/kaggle/working/seq2seqwattn.pth')\n    \n        # Save as artifact for version control.\n        run = wandb.init(project='machine-translator')\n        artifact = wandb.Artifact('seq2seqwattn', type='model')\n        artifact.add_file('/kaggle/working/seq2seqwattn.pth')\n        run.log_artifact(artifact)\n        run.finish()\n\n    train_losses.append(train_loss)\n    val_losses.append(valid_loss)","metadata":{"execution":{"iopub.status.busy":"2025-02-15T17:48:56.045793Z","iopub.execute_input":"2025-02-15T17:48:56.046040Z","execution_failed":"2025-02-15T23:45:51.110Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:20<00:00,  1.84it/s]\nEvaluating: 100%|██████████| 313/313 [00:49<00:00,  6.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1:\n  Train Loss: 7.091\n  Valid Loss: 7.098\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_181807-a3cph3sy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/a3cph3sy' target=\"_blank\">breathtaking-tulip-8</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/a3cph3sy' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/a3cph3sy</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">breathtaking-tulip-8</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/a3cph3sy' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/a3cph3sy</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_181807-a3cph3sy/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:18<00:00,  1.84it/s]\nEvaluating: 100%|██████████| 313/313 [00:49<00:00,  6.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2:\n  Train Loss: 7.061\n  Valid Loss: 7.105\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_184724-um6fjrj6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/um6fjrj6' target=\"_blank\">warm-admirer-9</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/um6fjrj6' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/um6fjrj6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">warm-admirer-9</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/um6fjrj6' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/um6fjrj6</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_184724-um6fjrj6/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:31<00:00,  1.83it/s]\nEvaluating: 100%|██████████| 313/313 [00:49<00:00,  6.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3:\n  Train Loss: 7.057\n  Valid Loss: 7.101\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_191654-34o4gssy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/34o4gssy' target=\"_blank\">wooing-date-10</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/34o4gssy' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/34o4gssy</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wooing-date-10</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/34o4gssy' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/34o4gssy</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_191654-34o4gssy/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:25<00:00,  1.83it/s]\nEvaluating: 100%|██████████| 313/313 [00:48<00:00,  6.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4:\n  Train Loss: 7.054\n  Valid Loss: 7.105\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_194617-pxcuxejx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/pxcuxejx' target=\"_blank\">tender-admirer-11</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/pxcuxejx' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/pxcuxejx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">tender-admirer-11</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/pxcuxejx' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/pxcuxejx</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_194617-pxcuxejx/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:27<00:00,  1.83it/s]\nEvaluating: 100%|██████████| 313/313 [00:49<00:00,  6.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5:\n  Train Loss: 7.054\n  Valid Loss: 7.094\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_201542-wcl7w5en</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/wcl7w5en' target=\"_blank\">sweet-heartthrob-12</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/wcl7w5en' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/wcl7w5en</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sweet-heartthrob-12</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/wcl7w5en' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/wcl7w5en</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_201542-wcl7w5en/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:28<00:00,  1.83it/s]\nEvaluating: 100%|██████████| 313/313 [00:48<00:00,  6.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6:\n  Train Loss: 7.053\n  Valid Loss: 7.098\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_204509-bule2c8h</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/bule2c8h' target=\"_blank\">divine-smooch-13</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/bule2c8h' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/bule2c8h</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">divine-smooch-13</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/bule2c8h' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/bule2c8h</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_204509-bule2c8h/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:27<00:00,  1.83it/s]\nEvaluating: 100%|██████████| 313/313 [00:48<00:00,  6.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7:\n  Train Loss: 7.052\n  Valid Loss: 7.102\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_211434-vu8evank</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/vu8evank' target=\"_blank\">moonlit-violet-14</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/vu8evank' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/vu8evank</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">moonlit-violet-14</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/vu8evank' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/vu8evank</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_211434-vu8evank/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:27<00:00,  1.83it/s]\nEvaluating: 100%|██████████| 313/313 [00:48<00:00,  6.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8:\n  Train Loss: 7.052\n  Valid Loss: 7.105\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_214359-thxnu4zc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/thxnu4zc' target=\"_blank\">enthusiastic-hug-15</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/thxnu4zc' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/thxnu4zc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">enthusiastic-hug-15</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/thxnu4zc' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/thxnu4zc</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_214359-thxnu4zc/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:20<00:00,  1.84it/s]\nEvaluating: 100%|██████████| 313/313 [00:48<00:00,  6.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9:\n  Train Loss: 7.052\n  Valid Loss: 7.101\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_221318-2sy3u7rw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/2sy3u7rw' target=\"_blank\">ecstatic-etchings-16</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/2sy3u7rw' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/2sy3u7rw</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ecstatic-etchings-16</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/2sy3u7rw' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/2sy3u7rw</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_221318-2sy3u7rw/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 3125/3125 [28:24<00:00,  1.83it/s]\nEvaluating: 100%|██████████| 313/313 [00:48<00:00,  6.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10:\n  Train Loss: 7.051\n  Valid Loss: 7.108\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_224239-podm0os8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/podm0os8' target=\"_blank\">desired-date-17</a></strong> to <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/podm0os8' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/podm0os8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">desired-date-17</strong> at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/podm0os8' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator/runs/podm0os8</a><br> View project at: <a href='https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator' target=\"_blank\">https://wandb.ai/longluv1605-institute-for-artificial-intelligence/machine-translator</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250215_224239-podm0os8/logs</code>"},"metadata":{}},{"name":"stderr","text":"Training:  85%|████████▍ | 2648/3125 [23:55<04:02,  1.97it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/seq2seq.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/working/seq2seq.pth\", \n                                 map_location=torch.device(\"cpu\"),\n                                 weights_only=True))\nmodel.eval()  ","metadata":{"execution":{"execution_failed":"2025-02-15T23:45:51.110Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndef translate_sentence(sentence, sp_en, trg_vocab, model, device, max_len=128):\n    model.to(device).eval()\n    \n    # Tokenize input using SentencePiece\n    tokens = sp_en.encode(sentence, out_type=str)  # Tokenize\n    print(\"Tokenized input:\", tokens)\n    \n    # Chuyển token thành chỉ mục (ID)\n    src_indexes = sp_en.encode(sentence)  # SentencePiece auto convert to ID\n    src_tensor = torch.tensor(src_indexes, dtype=torch.long).unsqueeze(0).to(device)  # [1, seq_len]\n    with torch.inference_mode():\n        _, hidden = model.encoder(src_tensor)  # Encode input\n    \n    trg_indexes = [trg_vocab['stoi'][\"<s>\"]]  # Begin with <sos>\n    for _ in range(max_len):\n        trg_tensor = torch.tensor([trg_indexes[-1]], dtype=torch.long).to(device)  # [1]\n        with torch.inference_mode():\n            output, hidden = model.decoder(trg_tensor, hidden)  # Get output from decoder\n        pred_token = output.argmax(1).item()  # Get token has highest probs\n        trg_indexes.append(pred_token)\n\n        if pred_token == trg_vocab['stoi'][\"</s>\"]:  # End if <eos>\n            break\n\n    # Convert ID to word\n    trg_tokens = [trg_vocab['itos'][i] for i in trg_indexes]\n    return \" \".join(trg_tokens[1:-1])  # Remove <sos> and <eos>\n","metadata":{"execution":{"execution_failed":"2025-02-15T23:45:51.110Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trg_vocab = {\n    \"stoi\": {sp_vi.id_to_piece(i): i for i in range(sp_vi.get_piece_size())},\n    \"itos\": {i: sp_vi.id_to_piece(i) for i in range(sp_vi.get_piece_size())},\n}\n\nsentence = \"How are you?\"\ntranslated_sentence = translate_sentence(sentence, sp_en, trg_vocab, model, device=\"cpu\")\nprint(\"Translated:\", translated_sentence)\n","metadata":{"execution":{"execution_failed":"2025-02-15T23:45:51.110Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}